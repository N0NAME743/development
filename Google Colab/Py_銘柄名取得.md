
# âœ… æ—¢å­˜ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
symbols = sheet.col_values(1)[1:]  # Aåˆ—
existing_names = sheet.col_values(2)[1:]  # Båˆ—
existing_prices = sheet.col_values(3)[1:]  # Cåˆ—
existing_timestamps = sheet.col_values(4)[1:]  # Dåˆ—

# âœ… å‡ºåŠ›ç”¨ãƒªã‚¹ãƒˆ
names = ['Name']
prices = ['Price']
timestamps = ['Time']
failed_symbols = []
updated_count = 0
start_time = time.time()

# âœ… ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ«ãƒ¼ãƒ—
for i, symbol in enumerate(symbols):
    full_symbol = f"{symbol}.T"

    if i > 0 and i % 100 == 0:
        elapsed = time.time() - start_time
        avg = elapsed / i
        rem = avg * (len(symbols) - i)
        print(f"ğŸ”„ {i}ä»¶å‡¦ç†ä¸­â€¦ æ‰€è¦: {elapsed:.1f}s / æ®‹ã‚Šäºˆæƒ³: ç´„{rem/60:.1f}åˆ†")

    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆ©ç”¨
    if full_symbol in cache_df.index:
        row = cache_df.loc[full_symbol]
        names.append(sanitize_value(row["Name"]))
        prices.append(sanitize_value(row["Price"]))
        if i < len(existing_timestamps) and existing_timestamps[i].strip():
            timestamps.append(existing_timestamps[i])
        else:
            timestamps.append(row["Time"])
        continue

    # æ–°è¦å–å¾—
    try:
        ticker = yf.Ticker(full_symbol)
        info = ticker.info
        name = info.get("shortName", "å–å¾—å¤±æ•—")
        hist = ticker.history(period="5d")
        close_price = hist["Close"].dropna().iloc[-1] if not hist.empty else "N/A"
        if name == "å–å¾—å¤±æ•—" or close_price == "N/A":
            failed_symbols.append(symbol)
    except:
        name = "ã‚¨ãƒ©ãƒ¼"
        close_price = "N/A"
        failed_symbols.append(symbol)

    names.append(name)
    prices.append(close_price)
    timestamps.append(now_str)
    cache_df.loc[full_symbol] = [name, close_price, now_str]
    updated_count += 1

# âœ… ã‚·ãƒ¼ãƒˆã«åæ˜ ï¼ˆBã€œDåˆ—ï¼‰
sheet.update(range_name="B1", values=[[v] for v in names])
sheet.update(range_name="C1", values=[[v] for v in prices])
sheet.update(range_name="D1", values=[[v] for v in timestamps])

# âœ… ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜
cache_df.sort_index(inplace=True)
cache_df.to_csv(CACHE_FILE, encoding="utf-8-sig")
print(f"ğŸ’¾ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜å®Œäº†: {CACHE_FILE}")

# âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«å
backup_title = f"{spreadsheet_title}_{today_str}"

# âœ… æ—¢å­˜ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒã‚ã‚Œã°å‰Šé™¤ï¼ˆDrive APIã‚’ä½¿ç”¨ï¼‰
try:
    existing_files = drive_service.files().list(
        q=f"name='{backup_title}' and mimeType='application/vnd.google-apps.spreadsheet'",
        fields="files(id)"
    ).execute()

    if existing_files["files"]:
        file_id = existing_files["files"][0]["id"]
        drive_service.files().delete(fileId=file_id).execute()
        print(f"ğŸ—‘ï¸ æ—¢å­˜ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å‰Šé™¤: {backup_title}")
except Exception as e:
    print(f"âš ï¸ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")

# âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆï¼ˆæ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
backup_sheet = gc.create(backup_title)
backup_ws = backup_sheet.get_worksheet(0)  # âœ… å¿…ãšã“ã“ã§å®šç¾©
data = sheet.get_all_values()
backup_ws.update(range_name="A1", values=data)

print(f"ğŸ“ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆå®Œäº†: {backup_title}")

# âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å…ƒã®ãƒ•ã‚©ãƒ«ãƒ€ã«ç§»å‹•
try:
    # å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã®è¦ªãƒ•ã‚©ãƒ«ãƒ€ã‚’å–å¾—
    original_file = drive_service.files().get(fileId=spreadsheet_id, fields='parents').execute()
    parent_folder_id = original_file.get('parents', [None])[0]

    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®IDå–å¾—
    result = drive_service.files().list(q=f"name='{backup_title}'", fields="files(id)").execute()
    backup_id = result["files"][0]["id"]

    # ãƒ«ãƒ¼ãƒˆã‹ã‚‰å‰Šé™¤ã€è¦ªãƒ•ã‚©ãƒ«ãƒ€ã«è¿½åŠ 
    drive_service.files().update(
        fileId=backup_id,
        addParents=parent_folder_id,
        removeParents="root",
        fields="id, parents"
    ).execute()

    print(f"ğŸ“‚ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å…ƒã®ãƒ•ã‚©ãƒ«ãƒ€ã«ç§»å‹•å®Œäº†ï¼ˆID: {parent_folder_id}ï¼‰")
except Exception as e:
    print(f"âš ï¸ ãƒ•ã‚©ãƒ«ãƒ€ç§»å‹•ã‚¨ãƒ©ãƒ¼: {e}")

# âœ… å®Ÿè¡Œå®Œäº†ãƒ­ã‚°
elapsed = time.time() - start_time
print("âœ… ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»ä¿å­˜ã™ã¹ã¦å®Œäº†ï¼")
print(f"ğŸ“„ å…ƒãƒ•ã‚¡ã‚¤ãƒ«å: {spreadsheet_title}")
print(f"ğŸ†• æ–°è¦å–å¾—æ•°: {updated_count} è¡Œ")
print(f"â±ï¸ å‡¦ç†æ™‚é–“: {elapsed:.1f} ç§’")

if failed_symbols:
    from collections import defaultdict

    grouped = defaultdict(list)
    for code in failed_symbols:
        try:
            prefix = int(code) // 1000 * 1000  # â† 1,000å˜ä½ã§åˆ†é¡
            grouped[f"{prefix}ç•ªå°"].append(code)
        except:
            grouped["ä¸æ˜"].append(code)

    print(f"âš ï¸ å–å¾—å¤±æ•—éŠ˜æŸ„ï¼ˆ{len(failed_symbols)}ä»¶ï¼‰:")
    for group in sorted(grouped.keys()):
        print(f"{group}: [{', '.join(grouped[group])}]")
else:
    print("ğŸ‰ å…¨éŠ˜æŸ„æ­£å¸¸ã«å–å¾—å®Œäº†ï¼")