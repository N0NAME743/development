# ================================
# Sec1ï½œã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
# ================================

!pip install --upgrade gspread gspread_dataframe google-auth yfinance --quiet

import os
import pandas as pd
import yfinance as yf
import gspread
from google.colab import auth
from gspread_dataframe import get_as_dataframe, set_with_dataframe
from googleapiclient.discovery import build
from googleapiclient.http import MediaInMemoryUpload
from google.auth.transport.requests import Request
from datetime import datetime, timezone, timedelta
import google.auth
from google.colab import drive
import time
from collections import defaultdict

# ================================
# Sec2ï½œå®šç¾©ãƒ»é–¢æ•°
# ================================

SAVE_PATH = "drive/MyDrive/ColabNotebooks/éŠ˜æŸ„åˆ†æ/signal"  # ğŸ”§ ä¿å­˜å…ˆã®ãƒ‘ã‚¹ã‚’æ­£ã—ãè¨­å®š
BACKUP_SUBFOLDER = "backup"  # ğŸ”§ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¯ã“ã®ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã«

# GoogleDriveé–¢æ•°
def mount_drive():
    drive.mount('/content/drive')

def authenticate_services():
    auth.authenticate_user()
    creds, _ = google.auth.default()
    return creds, gspread.authorize(creds), creds

def get_drive_folder_id_by_path(path, creds):
    service = build('drive', 'v3', credentials=creds)
    parts = path.strip("/").split("/")
    parent_id = 'root'
    for part in parts:
        query = f"name='{part}' and mimeType='application/vnd.google-apps.folder' and '{parent_id}' in parents and trashed=false"
        results = service.files().list(q=query, spaces='drive', fields='files(id, name)').execute()
        files = results.get('files', [])
        if files:
            parent_id = files[0]['id']
        else:
            file_metadata = {
                'name': part,
                'mimeType': 'application/vnd.google-apps.folder',
                'parents': [parent_id]
            }
            file = service.files().create(body=file_metadata, fields='id').execute()
            parent_id = file['id']
    return parent_id, service

def delete_existing_file_by_name(drive_service, folder_id, file_name):
    query = f"'{folder_id}' in parents and name = '{file_name}' and mimeType = 'application/vnd.google-apps.spreadsheet'"
    results = drive_service.files().list(q=query, fields="files(id, name)").execute()
    files = results.get('files', [])
    for file in files:
        drive_service.files().delete(fileId=file['id']).execute()

def create_spreadsheet_in_folder(title, folder_id, creds):
    drive_service = build("drive", "v3", credentials=creds)
    file_metadata = {
        "name": title,
        "mimeType": "application/vnd.google-apps.spreadsheet",
        "parents": [folder_id]
    }
    file = drive_service.files().create(body=file_metadata, fields="id").execute()
    return file["id"]

# æ—¥ä»˜ã®å–å¾—
def get_today_str():
    JST = timezone(timedelta(hours=9))
    now = datetime.now(JST)
    return now.strftime("%Y-%m-%d"), now.strftime("%Y-%m-%d %H:%M:%S")

# ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®Colum
def reorder_columns(df, preferred_order):
    existing_cols = [col for col in preferred_order if col in df.columns]
    other_cols = [col for col in df.columns if col not in existing_cols]
    return df[existing_cols + other_cols]

def clean_dataframe_columns(df, expected_cols):
    """
    DataFrameã‹ã‚‰é‡è¤‡åˆ—ï¼ˆä¾‹: 'MultiSign.1'ï¼‰ã‚’å–ã‚Šé™¤ãã€åˆ—é †ã‚’expected_colsã«æ•´ãˆã‚‹ã€‚
    """
    # 1. æœŸå¾…ã•ã‚Œã‚‹åˆ—åã«å¯¾ã—ã¦ã€.1 ã‚„ .2 ãŒã¤ã„ãŸé‡è¤‡åˆ—ãŒã‚ã‚Œã°å‰Šé™¤
    deduped_cols = {}
    for col in df.columns:
        base_col = col.split('.')[0]
        if base_col not in deduped_cols:
            deduped_cols[base_col] = col  # æœ€åˆã«å‡ºã¦ããŸæ­£è¦åã‚’æ¡ç”¨

    df = df[list(deduped_cols.values())]

    # 2. åˆ—é †ã‚’expected_colsã®é †ã«æ•´ãˆã‚‹ï¼ˆå­˜åœ¨ã™ã‚‹åˆ—ã®ã¿ï¼‰
    df = df[[col for col in expected_cols if col in df.columns]]

    return df

# Commentåˆ¤å®š
def format_signals_to_comment(signals, close=None, ma25=None, adx_value=None):
    phrases = []
    warnings = []
    score = 0

    # --- MACD + å‡ºæ¥é«˜ ---
    if "MACD" in signals and "å‡ºæ¥é«˜â†‘" in signals:
        phrases.append("MACDãŒé™½è»¢ã—ã€å‡ºæ¥é«˜ã®å¢—åŠ ã¨ã¨ã‚‚ã«è²·ã„åœ§åŠ›ã®é«˜ã¾ã‚ŠãŒè¦‹ã‚‰ã‚Œã¾ã™ã€‚")
        score += 3
    elif "MACD" in signals:
        phrases.append("MACDãŒé™½è»¢ã—ã€çŸ­æœŸçš„ãªä¸Šæ˜‡ã®å…†ã—ãŒã‚ã‚Šã¾ã™ã€‚")
        score += 2

    # --- ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ã‚¯ãƒ­ã‚¹ ---
    if "5MA>25MA" in signals:
        phrases.append("ç§»å‹•å¹³å‡ç·šã®ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ã‚¯ãƒ­ã‚¹ãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚")
        score += 2

    # --- RSIåç™º ---
    if "RSIåç™º" in signals:
        if close is not None and ma25 is not None and close < ma25:
            phrases.append("RSIãŒåç™ºã—ã¦ãŠã‚Šã€åº•æ‰“ã¡ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        else:
            phrases.append("RSIãŒåç™ºã—ã¦ã„ã¾ã™ãŒã€ã‚„ã‚„é«˜å€¤åœã®ãŸã‚æ…é‡ã«è¦‹æ¥µã‚ãŸã„ã¨ã“ã‚ã§ã™ã€‚")
        score += 1.5

    # --- é«˜å€¤çªç ´ ---
    if "é«˜å€¤çªç ´" in signals:
        phrases.append("ç›´è¿‘é«˜å€¤ã‚’ãƒ–ãƒ¬ã‚¤ã‚¯ã—ã€ãƒˆãƒ¬ãƒ³ãƒ‰ç¶™ç¶šã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        score += 2

    # --- ãƒœãƒƒã‚¯ã‚¹ãƒ»ä¸‰è§’ ---
    if "ãƒœãƒƒã‚¯ã‚¹ç›¸å ´" in signals:
        phrases.append("ãƒœãƒƒã‚¯ã‚¹ç›¸å ´å†…ã®å‹•ããŒç¶šã„ã¦ãŠã‚Šã€ãƒ¬ãƒ³ã‚¸ã®ä¸Šé™ã‚„ä¸‹é™ã«æ³¨ç›®ãŒé›†ã¾ã‚Šã¾ã™ã€‚")
        score += 0.5
    if "ä¸‰è§’ä¿ã¡åˆã„" in signals:
        phrases.append("ä¸‰è§’ä¿ã¡åˆã„ã®å½¢çŠ¶ã‚’è¦‹ã›ã¦ãŠã‚Šã€è¿‘ã„ã†ã¡ã«ãƒ–ãƒ¬ã‚¤ã‚¯ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        score += 0.5

    # --- ADXã®æ–‡è„ˆè©•ä¾¡ ---
    if adx_value is not None:
        if adx_value >= 40:
            if "MACD" in signals or "5MA>25MA" in signals:
                phrases.append("ãƒˆãƒ¬ãƒ³ãƒ‰ãŒéå¸¸ã«å¼·ãã€è²·ã„åœ§åŠ›ãŒç¶™ç¶šã—ã¦ã„ã¾ã™ã€‚")
                score += 2
            else:
                warnings.append("ADXãŒé«˜ãã€ãƒˆãƒ¬ãƒ³ãƒ‰ã¯å¼·ã„ã§ã™ãŒæ–°ãŸãªè²·ã„ã‚µã‚¤ãƒ³ã¯é™å®šçš„ã§ã™ã€‚")
                score += 0.5
        elif adx_value >= 25:
            if "MACD" in signals or "5MA>25MA" in signals:
                phrases.append("ä¸­ç¨‹åº¦ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã«åŠ ãˆã€ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ã‚‚å¥½è»¢ã—ã¦ã„ã¾ã™ã€‚")
                score += 1.5
            else:
                warnings.append("ADXã¯ã‚„ã‚„é«˜ã‚ã§ã™ãŒã€ä»–ã®ã‚·ã‚°ãƒŠãƒ«ã¨ã®é€£å‹•ã¯å¼±ã‚ã§ã™ã€‚")
                score += 0.5

    # --- ä¹–é›¢ç‡ã®æ‰±ã„ ---
    for s in signals:
        if "ä¹–é›¢ç‡" in s:
            try:
                val = float(s.replace("ä¹–é›¢ç‡", "").replace("%", ""))
                if abs(val) >= 10:
                    warnings.append(f"{s} ã«é”ã—ã¦ãŠã‚Šã€éç†±æ„ŸãŒã‚ã‚Šã¾ã™ã€‚")
                    score += 0.5
                else:
                    phrases.append(f"{s} ã®çŠ¶æ…‹ã§ã™ã€‚")
                    score += 0.5
            except:
                continue

    # --- å‡ºåŠ›å‡¦ç† ---
    if not phrases and not warnings:
        return "æ˜ç¢ºãªè²·ã„ã‚µã‚¤ãƒ³ã¯è¦‹ã‚‰ã‚Œã¾ã›ã‚“ã€‚", 0

    final_comment = " ".join(phrases)
    if warnings:
        final_comment += " " + " ".join(warnings)

    return final_comment, round(score, 1)

def analyze_stock(hist):
    signals = []
    trend = "ä¸æ˜"

    close = hist["Close"]
    ma5 = close.rolling(window=5).mean()
    ma25 = close.rolling(window=25).mean()
    ema12 = close.ewm(span=12).mean()
    ema26 = close.ewm(span=26).mean()
    macd = ema12 - ema26
    signal_line = macd.ewm(span=9).mean()

    delta = close.diff()
    up = delta.clip(lower=0)
    down = -delta.clip(upper=0)
    avg_gain = up.rolling(window=14).mean()
    avg_loss = down.rolling(window=14).mean()
    rs = avg_gain / avg_loss
    rsi = 100 - (100 / (1 + rs))

    vol_ma5 = hist["Volume"].rolling(window=5).mean()
    max_high = close.rolling(window=20).max()

    high = close + 1.0
    low = close - 1.0
    plus_dm = high.diff()
    minus_dm = low.diff().abs()
    tr = pd.concat([
        high - low,
        (high - close.shift()).abs(),
        (low - close.shift()).abs()
    ], axis=1).max(axis=1)
    atr = tr.rolling(window=14).mean()
    plus_di = 100 * (plus_dm.rolling(window=14).mean() / atr)
    minus_di = 100 * (minus_dm.rolling(window=14).mean() / atr)
    dx = (abs(plus_di - minus_di) / (plus_di + minus_di)) * 100
    adx = dx.rolling(window=14).mean()

    range20 = close.rolling(window=20).max() - close.rolling(window=20).min()
    range_std = range20.rolling(window=5).std()

    # === ã‚·ã‚°ãƒŠãƒ«æŠ½å‡º ===
    if macd.iloc[-2] < signal_line.iloc[-2] and macd.iloc[-1] > signal_line.iloc[-1] and macd.iloc[-1] > 0:
        signals.append("MACD")
    if ma5.iloc[-2] < ma25.iloc[-2] and ma5.iloc[-1] > ma25.iloc[-1] and close.iloc[-1] > ma25.iloc[-1]:
        signals.append("5MA>25MA")
    if rsi.iloc[-2] < 30 and rsi.iloc[-1] > 30 and rsi.iloc[-1] > rsi.iloc[-2] + 5:
        signals.append("RSIåç™º")
    if hist["Volume"].iloc[-1] > 1.5 * vol_ma5.iloc[-1] and hist["Volume"].iloc[-1] > hist["Volume"].iloc[-2]:
        signals.append("å‡ºæ¥é«˜â†‘")
    if close.iloc[-1] > max_high.iloc[-2] * 1.01:
        signals.append("é«˜å€¤çªç ´")

    disparity = ((close.iloc[-1] - ma25.iloc[-1]) / ma25.iloc[-1]) * 100
    if abs(disparity) > 5:
        signals.append(f"ä¹–é›¢ç‡{disparity:+.1f}%")
    if adx.iloc[-1] >= 40:
        signals.append("ADXå¼·â†‘")
    elif adx.iloc[-1] >= 25:
        signals.append("ADXä¸­â†‘")
    if range_std.iloc[-1] < 1.0:
        signals.append("ãƒœãƒƒã‚¯ã‚¹ç›¸å ´")
    if range_std.iloc[-1] < 0.5 and not range_std.iloc[-2] < 0.5:
        signals.append("ä¸‰è§’ä¿ã¡åˆã„")

    # === ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†é¡ ===
    adx_last = adx.iloc[-1] if not adx.empty else None
    if adx_last is not None:
        if adx_last < 20:
            trend = "æ¨ªã°ã„"
        elif ("MACD" in signals or "5MA>25MA" in signals) and adx_last >= 25:
            trend = "ä¸Šæ˜‡"
        else:
            trend = "ä¸æ˜"

    # â˜…ã“ã“ã§æœ€æ–°å€¤ã‚’å–å¾—
    rsi_last = rsi.iloc[-1] if not rsi.empty else None
    # disparityã¯ã™ã§ã«è¨ˆç®—æ¸ˆã¿

    score, overbought = calc_score(signals, adx_last, rsi_last, disparity)
    return signals, adx_last, trend, score, rsi_last, disparity, overbought

# ã‚¹ã‚³ã‚¢åˆ¤å®šå‡¦ç†

def calc_score(signals, adx_value, rsi_value=None, disparity_value=None):
    score = 0.0
    # æ—¢å­˜ã®åŠ ç‚¹ãƒ­ã‚¸ãƒƒã‚¯
    if "å‡ºæ¥é«˜â†‘" in signals:
        score += 1.0
    if "é«˜å€¤çªç ´" in signals:
        score += 1.5
    has_disparity = any(
        "ä¹–é›¢ç‡" in s and float(s.replace("ä¹–é›¢ç‡", "").replace("%", "").replace("+", "")) >= 10
        for s in signals
    )
    if has_disparity:
        score += 1.0
    if adx_value is not None:
        if adx_value >= 40:
            score += 1.5
        elif adx_value >= 25:
            score += 1.0

    # --- éç†±æ„Ÿã«ã‚ˆã‚‹æ¸›ç‚¹ ---
    overbought = False
    if rsi_value is not None and rsi_value >= 70:
        score -= 1.0
        overbought = True
    if disparity_value is not None and abs(disparity_value) >= 10:
        score -= 1.0
        overbought = True

    return max(score, 0), overbought  # ã‚¹ã‚³ã‚¢ã¯0æœªæº€ã«ãªã‚‰ãªã„ã‚ˆã†ã«

def judge_action_by_score(score):
    """
    ã‚¹ã‚³ã‚¢ã«å¿œã˜ã¦ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¿”ã™ï¼ˆ3åˆ†é¡ï¼‰
    0ï½1   ï¼šã€Œé™è¦³ï¼ˆã‚¨ãƒ³ãƒˆãƒªãƒ¼éæ¨å¥¨ï¼‰ã€
    2ï½3   ï¼šã€Œä¸­ç«‹ï¼ˆæ…é‡ã«æ¤œè¨ï¼‰ã€
    4ï½5   ï¼šã€Œç©æ¥µæ¤œè¨ï¼ˆè²·ã„ç›®ç·šå¼·ï¼‰ã€
    """
    if 4.0 <= score <= 5.0:
        return "ç©æ¥µæ¤œè¨ï¼ˆè²·ã„ç›®ç·šå¼·ï¼‰"
    elif 2.0 <= score < 4.0:
        return "ä¸­ç«‹ï¼ˆæ…é‡ã«æ¤œè¨ï¼‰"
    elif 0.0 <= score < 2.0:
        return "é™è¦³ï¼ˆã‚¨ãƒ³ãƒˆãƒªãƒ¼éæ¨å¥¨ï¼‰"
    else:
        return "ã‚¹ã‚³ã‚¢ç•°å¸¸"

def analyze_trend_and_score(signals, adx_value):
    score = calc_score(signals, adx_value)
    # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®š
    if 4.0 <= score <= 5.0:
        trend_label = "ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰"
    elif 2.0 <= score < 4.0:
        trend_label = "ã‚„ã‚„ä¸Šæ˜‡å‚¾å‘"
    elif 0.0 <= score < 2.0:
        trend_label = "æ¨ªã°ã„ã€œè­¦æˆ’"
    else:
        trend_label = "ãƒˆãƒ¬ãƒ³ãƒ‰ä¸æ˜"
    score_str = f"{round(score, 1)}/5.0"
    mark = "â—¯" if 4.0 <= score <= 5.0 else "âœ•"
    return trend_label, score_str, mark

def analyze_and_judge(hist, stock_name=""):
    signals, adx_last, trend, trend_score = analyze_stock(hist)
    score = calc_score(signals, adx_last)
    comment = format_signals_to_comment(signals,
                                        close=hist["Close"].iloc[-1],
                                        ma25=hist["Close"].rolling(window=25).mean().iloc[-1],
                                        adx_value=adx_last)[0]
    action = judge_action_by_score(score)
    print(f"ã€{stock_name}ã€‘")
    print(f"ã‚·ã‚°ãƒŠãƒ«: {signals}")
    print(f"ã‚¹ã‚³ã‚¢: {score}/5.0")
    print(f"æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {action}")
    print(f"ã‚³ãƒ¡ãƒ³ãƒˆ: {comment}")
    print("-" * 40)
    return {
        "stock": stock_name,
        "signals": signals,
        "score": score,
        "action": action,
        "comment": comment
    }

import numpy as np

def symbol_to_num(symbol):
    # .Tã‚’é™¤å»ã—ã€æ•°å€¤éƒ¨åˆ†ã®ã¿æŠ½å‡º
    s = str(symbol).replace('.T', '')
    try:
        return int(float(s))
    except ValueError:
        return np.nan  # æ•°å€¤åŒ–ã§ããªã„å ´åˆã¯NaN

def process_all_sheets(spreadsheet_name, gc, drive_service, folder_id_main, folder_id_backup):
    global SAVE_PATH
    global sheet_process_logs
    today_str, timestamp_str = get_today_str()
    spreadsheet = gc.open(spreadsheet_name)
    sheet_list = spreadsheet.worksheets()

    all_dfs = []  # â† ã“ã“ã§ãƒªã‚¹ãƒˆã‚’åˆæœŸåŒ–

    for worksheet in sheet_list:
        start_time_sheet = time.time()  # â† ã“ã“ã§æ¸¬å®šé–‹å§‹
        sheet_name = worksheet.title
        print(f"ğŸ” å‡¦ç†ä¸­: {sheet_name}")
        df = get_as_dataframe(worksheet, evaluate_formulas=True)

        if "Symbol" not in df.columns:
            print(f"âš ï¸ {sheet_name} ã«Symbolåˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            continue

        # åˆ—ã®åˆæœŸåŒ–å‡¦ç†
        for col in ["Name", "Time", "Price", "TrendScore", "Sign", "MultiSign", "Action"]:
            if col not in df.columns:
                df[col] = pd.Series([""] * len(df), dtype="object")
            else:
                df[col] = df[col].astype("object")

        df["Time"] = df["Time"].astype(str)

        for i, row in df.iterrows():
            raw_symbol = None
            try:
                # ã‚·ãƒ³ãƒœãƒ«å‰å‡¦ç†
                raw_symbol = str(row["Symbol"]).strip().replace("$", "").replace(".T", "")
                if "." in raw_symbol: raw_symbol = raw_symbol.split(".")[0]
                code = raw_symbol.zfill(4)
                ticker = f"{code}.T"

                # æ ªä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—
                stock = yf.Ticker(ticker)
                hist = stock.history(period="3mo")
                if hist.empty or len(hist) < 30:
                    print(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿ä¸è¶³: {ticker} - ãƒ’ã‚¹ãƒˆãƒªã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿{len(hist)}ä»¶")
                    continue

                # åŸºæœ¬æƒ…å ±æ›´æ–°
                df.at[i, "Price"] = round(hist["Close"].iloc[-1], 2)
                if pd.isnull(row["Name"]) or row["Name"] == "":
                    df.at[i, "Name"] = stock.info.get("shortName", "")

                # åˆ†æå‡¦ç†
                signals, adx_last, trend, score, rsi_last, disparity, overbought = analyze_stock(hist)
                df.at[i, "Sign"] = "âœ… " + ", ".join(signals) if signals else ""

                # ã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆ
                comment, _ = format_signals_to_comment(
                    signals,
                    close=hist["Close"].iloc[-1],
                    ma25=hist["Close"].rolling(25).mean().iloc[-1],
                    adx_value=adx_last  # â† adx_lastã‚’ä½¿ç”¨
                )
                df.at[i, "MultiSign"] = comment
                df.at[i, "Time"] = timestamp_str

                # ã‚¹ã‚³ã‚¢è¨ˆç®—ã¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³åˆ¤å®š
                score, overbought = calc_score(signals, adx_last, rsi_last, disparity)
                df.at[i, "TrendScore"] = round(score, 1)

                action = judge_action_by_score(score)
                if overbought and action == "ç©æ¥µæ¤œè¨ï¼ˆè²·ã„ç›®ç·šå¼·ï¼‰":
                    action = "ä¸­ç«‹ï¼ˆéç†±æ„Ÿè­¦æˆ’ï¼‰"
                df.at[i, "Action"] = action

            except Exception as e:
                print(f"âš ï¸ ã‚¨ãƒ©ãƒ¼: {raw_symbol or 'ä¸æ˜'} - {e}")

        # ãƒ‡ãƒ¼ã‚¿æ•´å½¢
        df = reorder_columns(df, ["Symbol", "Name", "Time", "Price", "Action", "TrendScore", "Sign", "MultiSign"])
        df = clean_dataframe_columns(df, ["Symbol", "Name", "Time", "Price", "Action", "TrendScore", "Sign", "MultiSign"])
        df["Symbol"] = df["Symbol"].astype(str).str.replace(r"\.T$", "", regex=True) + ".T"

        all_dfs.append(df.copy())  # â† ãƒ‡ãƒ¼ã‚¿æ•´å½¢å¾Œã«è¿½åŠ 

        # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæ›´æ–°
        worksheet.clear()
        set_with_dataframe(worksheet, df.fillna(""))

        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
        new_sheet_title = f"Watchlist_{sheet_name}_{today_str}"
        try:
            delete_existing_file_by_name(drive_service, folder_id_backup, new_sheet_title)
            new_spreadsheet = gc.create(new_sheet_title, folder_id_backup)

            set_with_dataframe(new_spreadsheet.sheet1, df.fillna(""))
            print(f"âœ… å®Œäº†: {new_sheet_title}")
        except Exception as e:
            print(f"âŒ ä½œæˆå¤±æ•—: {new_sheet_title} - {e}")

        # ğŸ”„ å„ã‚·ãƒ¼ãƒˆå‡¦ç†ãƒ­ã‚°ã®è¨˜éŒ²ï¼ˆã‚·ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ—ã®æœ€å¾Œã«è¿½åŠ ï¼‰
        elapsed_sheet = time.time() - start_time_sheet  # â€» ã‚·ãƒ¼ãƒˆå‡¦ç†ã®æœ€åˆã§ start_time_sheet = time.time() ã‚’å®šç¾©ã—ã¦ãŠã
        sheet_process_logs.append({
            "sheet_name": sheet_name,
            "count": len(df),
            "elapsed": elapsed_sheet,
            "failures": [row["Symbol"] for i, row in df.iterrows() if "ã‚¨ãƒ©ãƒ¼" in str(row["MultiSign"]) or "å–å¾—å¤±æ•—" in str(row["Name"])]
        })

    # --- è¿½åŠ å‡¦ç†ã“ã“ã‹ã‚‰ ---
    if all_dfs:
        all_df = pd.concat(all_dfs, ignore_index=True)
        # æ•°å€¤å¤‰æ›å‡¦ç†ã‚’å³å¯†åŒ–
        filtered = all_df[pd.to_numeric(all_df["TrendScore"], errors="coerce").ge(3)].copy()
        filtered["SymbolNum"] = filtered["Symbol"].apply(symbol_to_num)
        filtered = filtered.sort_values("SymbolNum", na_position='last').drop("SymbolNum", axis=1)

        new_sheet_title = f"watchlist_signal_{today_str}"
        try:
            delete_existing_file_by_name(drive_service, folder_id_main, new_sheet_title)
            new_spreadsheet = gc.create(new_sheet_title, folder_id_main)
            set_with_dataframe(new_spreadsheet.sheet1, filtered.fillna(""))
            print(f"âœ… å®Œäº†: {new_sheet_title}")
        except Exception as e:
            print(f"âŒ ä½œæˆå¤±æ•—: {new_sheet_title} - {e}")
    else:
        print("âš ï¸ æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒ1ä»¶ã‚‚ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚watchlist_signalãƒ•ã‚¡ã‚¤ãƒ«ã¯ä½œæˆã•ã‚Œã¾ã›ã‚“ã€‚")
    # --- è¿½åŠ å‡¦ç†ã“ã“ã¾ã§ ---

    # å…¨å‡¦ç†çµ‚äº†å¾Œï¼ˆprint("ğŸ‰ ...")ã®å‰ï¼‰ã«è¿½åŠ 
    print("\nğŸ”¬ ãƒ‡ãƒãƒƒã‚°æƒ…å ±:")
    print(f"å…¨ã‚·ãƒ¼ãƒˆæ•°: {len(sheet_list)}")
    print(f"å‡¦ç†æ¸ˆã¿ã‚·ãƒ¼ãƒˆæ•°: {len(all_dfs)}")
    print(f"å…¨ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(all_df) if all_dfs else 0}")
    print(f"ãƒ•ã‚£ãƒ«ã‚¿å¾Œä»¶æ•°: {len(filtered) if all_dfs else 0}")
    print(f"ğŸ“ ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€IDï¼ˆmainï¼‰: {folder_id_main}")

    print("ğŸ‰ ã™ã¹ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ")


# ================================
# âœ… ãƒ¡ã‚¤ãƒ³å‡¦ç†é–¢æ•°
# ================================

def main():
    # ã‚ãªãŸã®Driveä¸Šã®ç›®çš„ãƒ•ã‚©ãƒ«ãƒ€IDã«å·®ã—æ›¿ãˆã¦ãã ã•ã„
    FOLDER_ID_MAIN = "1dFuJfNLSJ7tw43Ac9RKAqJ0yW49cLsIe"       # ColabNotebooks/éŠ˜æŸ„åˆ†æ/Signal
    FOLDER_ID_BACKUP = "1hN6fzMeT1ZB7I0jVRc9L_8HKIqI0Gi_W"     # ColabNotebooks/éŠ˜æŸ„åˆ†æ/Signal/backup

    spreadsheet_name = "watchlist"
    mount_drive()

    start_time = time.time()
    print("ğŸš€ å‡¦ç†é–‹å§‹")

    global sheet_process_logs
    sheet_process_logs = []  # â† ãƒ­ã‚°åˆæœŸåŒ–

    try:
        _, gc, creds = authenticate_services()

        # Google Drive APIã®ã‚µãƒ¼ãƒ“ã‚¹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        drive_service = build("drive", "v3", credentials=creds)

        # ğŸ“Œ ãƒ•ã‚©ãƒ«ãƒ€IDã‚’ãã®ã¾ã¾æ¸¡ã™ï¼ˆget_drive_folder_id_by_path ã‚’ä½¿ã‚ãªã„ï¼‰
        process_all_sheets(spreadsheet_name, gc, drive_service, FOLDER_ID_MAIN, FOLDER_ID_BACKUP)

    except Exception as e:
        print(f"âŒ é‡å¤§ã‚¨ãƒ©ãƒ¼: {e}")
        return

    elapsed = time.time() - start_time
    print("âœ… å…¨å‡¦ç†å®Œäº†ï¼")
    print(f"â±ï¸ æ‰€è¦æ™‚é–“: {elapsed:.1f} ç§’")

    # å„ã‚·ãƒ¼ãƒˆå˜ä½ã®ãƒ­ã‚°å‡ºåŠ›ï¼ˆçœç•¥ã›ãšå‡ºã™ï¼‰
    if sheet_process_logs:
        print("\nğŸ“Š ã‚·ãƒ¼ãƒˆã”ã¨ã®å‡¦ç†æ¦‚è¦:")
        for log in sheet_process_logs:
            print(f"\nğŸ“„ ã‚·ãƒ¼ãƒˆ: {log['sheet_name']}")
            print(f" - ä»¶æ•°: {log['count']} è¡Œ")
            print(f" - å‡¦ç†æ™‚é–“: {log['elapsed']:.1f} ç§’")
            if log['failures']:
                print(f" - âš ï¸ å¤±æ•—éŠ˜æŸ„: {len(log['failures'])} ä»¶")
                from collections import defaultdict
                grouped = defaultdict(list)
                for code in log['failures']:
                    try:
                        prefix = int(code) // 1000 * 1000
                        grouped[f"{prefix}ç•ªå°"].append(code)
                    except:
                        grouped["ä¸æ˜"].append(code)
                for group in sorted(grouped.keys()):
                    print(f"   ãƒ»{group}: [{', '.join(grouped[group])}]")
            else:
                print(" - ğŸ‰ å…¨éŠ˜æŸ„æ­£å¸¸ã«å–å¾—")
